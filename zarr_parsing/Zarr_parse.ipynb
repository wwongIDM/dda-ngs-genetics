{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages - have been installed in vcf virtual env\n",
    "import os, sys\n",
    "import zarr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import allel  \n",
    "import dask.array as da\n",
    "from itertools import compress\n",
    "import glob\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_zarr(chrom, zarr_path):\n",
    "    zarr_file = zarr_path + 'SNP_INDEL_Pf3D7_' + chrom + '_v3.zarr'\n",
    "    print(zarr_file)\n",
    "    callset = zarr.open(zarr_file, mode='r')\n",
    "    return(callset)\n",
    "\n",
    "def gt_subset(callset, variant_bool, sample_bool):\n",
    "    gt_zarr = callset['calldata/GT']\n",
    "    gt_dask = allel.GenotypeDaskArray(gt_zarr)\n",
    "    gt_daskSub = gt_dask.subset(variant_bool, sample_bool).compute()\n",
    "    return(gt_daskSub)\n",
    "\n",
    "def overlap_avail(user_pos_list, callset):\n",
    "    zarr_index   = callset['variants/POS'][:].tolist()\n",
    "    user_overlap =  [i in user_pos_list for i in zarr_index]\n",
    "    return(user_overlap)\n",
    "    \n",
    "def overlap_filter(user_snps, filter_snps):\n",
    "    return(user_snps & filter_snps)\n",
    "\n",
    "def user_snps(user_df, chrom):\n",
    "    user_sub = user_df[user_df['chr'].str.contains(chrom)]\n",
    "    return(user_sub[\"position\"].tolist())\n",
    "    \n",
    "def variant_filter(callset, vsqlod_min, num_alt):\n",
    "    quality_set = callset['variants/FILTER_PASS'][:]\n",
    "    snp_set = callset['variants/is_snp'][:]\n",
    "    vsqlod_set = callset['variants/VQSLOD'][:]  > vsqlod_min\n",
    "    alt_set = callset['variants/numalt'][:] < num_alt + 1 \n",
    "    variant_hq = quality_set & snp_set & vsqlod_set & alt_set\n",
    "    return(variant_hq)\n",
    "\n",
    "\n",
    "def allele_freq(callset, variant_bool, sample_bool, num_alt, chrom):\n",
    "    gt_daskSub = gt_subset(callset, variant_bool, sample_bool)\n",
    "    # count number of alleles\n",
    "    ac = gt_daskSub.count_alleles(max_allele=num_alt)\n",
    "    sub_af = ac/ac.sum(axis=1, keepdims=True)\n",
    "    sub_df = pd.DataFrame(sub_af,\n",
    "                 index=[\"Pf3D7_\" + chrom + \"_v3:\" + str(x) for x in np.array(callset['variants/POS'][:])[variant_bool]],\n",
    "                 columns=[\"REF\"] + [\"ALT\" + str(x) for x in range(1, num_alt + 1)])\n",
    "    return(sub_df)\n",
    "\n",
    "def gt_merge(list1, list2, j, callset, variant_bool):\n",
    "    dic = {-1:\"X\", \n",
    "           0: np.array(callset['variants/REF'][:])[variant_bool][j], \n",
    "           1: np.array(callset['variants/ALT'][:])[variant_bool][j,0], \n",
    "           2: np.array(callset['variants/ALT'][:])[variant_bool][j,1],\n",
    "           3: np.array(callset['variants/ALT'][:])[variant_bool][j,2]}\n",
    "    merged_list = []\n",
    "    for i in range(0, len(list1)):\n",
    "        if list1[i] == list2[i]:\n",
    "            if list1[i] == -1:\n",
    "                merged_list.append(\"X\")\n",
    "            else:\n",
    "                merged_list.append(list1[i])\n",
    "        else:\n",
    "            merged_list.append(\"N\") \n",
    "    merged_replace=[dic.get(n, n) for n in merged_list]  \n",
    "    return(merged_replace)\n",
    "\n",
    "def match_genotype(callset, variant_bool, sample_bool, chrom ):\n",
    "    gt_daskSub = gt_subset(callset, variant_bool, sample_bool)\n",
    "    data =[]\n",
    "    for j in range(0, len(gt_daskSub)):\n",
    "        data.append(gt_merge(gt_daskSub[j,:,0], gt_daskSub[j,:,1], j, callset, variant_bool))\n",
    "    gt_df = pd.DataFrame(data,\n",
    "                 index=[\"Pf3D7_\" + chrom + \"_v3:\" + str(x) for x in np.array(callset['variants/POS'][:])[variant_bool]],\n",
    "                 columns=list(compress(np.array(callset['samples']).tolist(), sample_bool)))\n",
    "    return(gt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the SNPs of interest - i.e. 24 barcode positions\n",
    "project_dir = 'C:/Users/wwong/Dropbox (IDM)/parasite_genetics/genomics/senegal'\n",
    "user_snp_file = os.path.join(project_dir, \"2008Daniels_BarcodePositions_Updated.txt\")\n",
    "user_snp_df = pd.read_csv(user_snp_file, sep='\\t', header=0)\n",
    "user_snp_df\n",
    "\n",
    "#user_samples = 'C:/Users/wwong/Dropbox (IDM)/parasite_genetics/genomics/senegal/pf3k_bc_sampleOverlap.txt'\n",
    "#with open(user_samples) as f:\n",
    "#    sampleList = f.read().splitlines() \n",
    "#print(sampleList[1:5])\n",
    "#print(len(sampleList))\n",
    "\n",
    "sampleList = ['SenP005.02','SenP008.04','SenP011.02','SenP019.04','SenP027.02','SenP031.01','SenP051.02','SenP060.02','SenT001.08']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/wwong/Dropbox (IDM)/parasite_genetics/genomics/pf3k_zarr/SNP_INDEL_Pf3D7_01_v3.zarr\n"
     ]
    }
   ],
   "source": [
    "project_dir = 'C:/Users/wwong/Dropbox (IDM)/parasite_genetics/genomics/senegal/'\n",
    "num_alt = 3\n",
    "genotypes, frequencies = [], []\n",
    "\n",
    "\n",
    "class Zarr_Parse():\n",
    "    def __init__(self, sample_list, position_df, chrom_list = [x for x in range(1,15)], zarr_directory = 'C:/Users/wwong/Dropbox (IDM)/parasite_genetics/genomics/pf3k_zarr/',):\n",
    "        self.zarr_directory = zarr_directory\n",
    "        self.zfile_chromosomes = [int(zfile.split('_')[-2]) for zfile in glob.glob(self.zarr_directory + '*.zarr')]\n",
    "        self.chromosomes = []\n",
    "        self.samples = sample_list\n",
    "        self.positions = position_df #dataframe, columns = ['chr', 'position']\n",
    "        self.callset = {}\n",
    "        self.variant_bools = {}\n",
    "        self.sample_bools = {}\n",
    "        self.freq = {}\n",
    "        self.genotypes = {}        \n",
    "        self.fields = defaultdict(dict)\n",
    "        \n",
    "        self.create_callset(chrom_list)\n",
    "        \n",
    "    def create_callset(self, chrom_list):\n",
    "        for chromosome in chrom_list:\n",
    "            if int(chromosome) in self.zfile_chromosomes:\n",
    "                self.chromosomes.append(chromosome)\n",
    "                chrom = \"{:02d}\".format(chromosome)\n",
    "                callset = read_zarr(chrom, self.zarr_directory)\n",
    "                self.callset[chromosome]= callset\n",
    "                \n",
    "                user_chrom_snps = user_snps(self.positions, chrom)\n",
    "                variant_bool = overlap_filter(overlap_avail(user_chrom_snps, callset), \n",
    "                                          variant_filter(callset, 2, num_alt))\n",
    "                self.variant_bools[chromosome] = variant_bool\n",
    "                \n",
    "                callset_samples = np.asarray(self.callset[chromosome]['samples']) #callset_samples\n",
    "                sample_bool = np.array([i in self.samples for i in callset_samples]) \n",
    "                self.sample_bools[chromosome] = sample_bool\n",
    "                \n",
    "                self.freq[chromosome] = allele_freq(callset, variant_bool, sample_bool, 3, chrom)\n",
    "                self.genotypes[chromosome] = match_genotype(callset, variant_bool, sample_bool, chrom)\n",
    "                \n",
    "    def extract_fields(self, dir1, field):\n",
    "        #works only for GT, DP, and AD only!\n",
    "        entry = '{dir1}/{field}'.format(dir1=dir1, field = field)\n",
    "        for chromosome in self.chromosomes:\n",
    "            if field in ['GT']:\n",
    "                dask = allel.GenotypeDaskArray(self.callset[chromosome][entry])\n",
    "                self.fields[entry][chromosome] = dask.subset(self.variant_bools[chromosome], self.sample_bools[chromosome]).compute()\n",
    "            elif field in ['DP']: #check the differentiation between AlleleCountsDaskarray and GenotypeDaskArray\n",
    "                dask = allel.AlleleCountsDaskArray(self.callset[chromosome][entry])\n",
    "                variant_selection = dask.compress(self.variant_bools[chromosome], axis=0).compute()\n",
    "                sample_selection = variant_selection[:, self.sample_bools[chromosome]]\n",
    "                self.fields[entry][chromosome] = sample_selection\n",
    "            elif field in ['AD']: #?? not sure why some things are Genotype/Allelecounts/ or simply an array\n",
    "                zarr_array =self.callset[chromosome][entry]\n",
    "                darray =da.from_zarr(zarr_array)\n",
    "                variant_selection=darray[self.variant_bools[chromosome]]\n",
    "                sample_selection=variant_selection[:,self.sample_bools[chromosome],:]\n",
    "                self.fields[entry][chromosome] = sample_selection\n",
    "    \n",
    "    def calculate_readdepth_proportions(self):\n",
    "        self.allele_props = {}\n",
    "        self.extract_fields('calldata', 'DP')\n",
    "        self.extract_fields('calldata', 'AD')\n",
    "        for chromosome in self.chromosomes:\n",
    "            allele_depths = np.asarray(self.fields['calldata/AD'][chromosome])\n",
    "            allele_depths[allele_depths == -1] = 0 #missing call considered same as 0\n",
    "            expanded_dim_depths = np.expand_dims(self.fields['calldata/DP'][chromosome], axis = 2) #expand the last dimension to be shape (position,samples,1) and allow direct division\n",
    "            self.allele_props[chromosome] = allele_depths / expanded_dim_depths\n",
    "\n",
    "        \n",
    "    def make_variant_call(self):\n",
    "        def call(stack):\n",
    "            if stack[1] > 0.9:\n",
    "                return stack[0]\n",
    "            else:\n",
    "                return 'mixed'    \n",
    "        self.variant_call = {}\n",
    "        self.calculate_readdepth_proportions()\n",
    "        self.variant_calls = {}\n",
    "        for chromosome in self.chromosomes:\n",
    "            max_idxes = np.argmax(self.allele_props[chromosome], axis = 2)\n",
    "            max_values = np.max(self.allele_props[chromosome], axis = 2)\n",
    "            stacked_array = np.stack((max_idxes, max_props), axis = 2)\n",
    "            self.variant_calls[chromosome] = np.apply_along_axis(call, 2, stacked_array)\n",
    "        #check reference status\n",
    "        \n",
    "        \n",
    "Z = Zarr_Parse(sampleList, user_snp_df)\n",
    "Z.extract_fields('calldata', 'GT')\n",
    "Z.calculate_readdepth_proportions()\n",
    "Z.make_variant_call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.        , 0.        , 0.        , 0.        ],\n",
       "        [0.02247191, 0.97752809, 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        ],\n",
       "        [1.        , 0.        , 0.        , 0.        ],\n",
       "        [1.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        ],\n",
       "        [1.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 1.        , 0.        , 0.        ],\n",
       "        [0.02083333, 0.97916667, 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        ],\n",
       "        [0.01282051, 0.98717949, 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        ]]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.allele_props[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([[0., 1., 1., 0., 0., 1., 0., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1.]])}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.variant_calls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
