{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing barcode variants from whole genome variant files\n",
    "\n",
    "Learn to subset variants from Zarr files that can be used in IDM models.\n",
    "\n",
    "The Zarr format is similar to HD5 that will allows to subset large files without loading into memory. For any whole genome sequencing file, variants in a population will be in a VCF format.\n",
    "\n",
    "Tutorials for guidance:\n",
    "\n",
    "http://alimanfoo.github.io/2016/06/10/scikit-allel-tour.html\n",
    "\n",
    "http://alimanfoo.github.io/2018/04/09/selecting-variants.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages - have been installed in vcf virtual env\n",
    "import os, sys\n",
    "import zarr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import allel  \n",
    "import dask.array as da\n",
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_zarr(chrom, zarr_path):\n",
    "    zarr_file = zarr_path + 'SNP_INDEL_Pf3D7_' + chrom + '_v3.zarr'\n",
    "    callset = zarr.open(zarr_file, mode='r')\n",
    "    return(callset)\n",
    "\n",
    "def gt_subset(callset, variant_bool, sample_bool):\n",
    "    gt_zarr = callset['calldata/GT']\n",
    "    gt_dask = allel.GenotypeDaskArray(gt_zarr)\n",
    "    gt_daskSub = gt_dask.subset(variant_bool, sample_bool).compute()\n",
    "    return(gt_daskSub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_avail(user_pos_list, callset):\n",
    "    zarr_index   = callset['variants/POS'][:].tolist()\n",
    "    user_overlap =  [i in user_pos_list for i in zarr_index]\n",
    "    return(user_overlap)\n",
    "    \n",
    "def overlap_filter(user_snps, filter_snps):\n",
    "    return(user_snps & filter_snps)\n",
    "\n",
    "def user_snps(user_df, chrom):\n",
    "    user_sub = user_df[user_df['chr'].str.contains(chrom)]\n",
    "    return(user_sub[\"position\"].tolist())\n",
    "    \n",
    "def variant_filter(callset, vsqlod_min, num_alt):\n",
    "    quality_set = callset['variants/FILTER_PASS'][:]\n",
    "    snp_set = callset['variants/is_snp'][:]\n",
    "    vsqlod_set = callset['variants/VQSLOD'][:]  > vsqlod_min\n",
    "    alt_set = callset['variants/numalt'][:] < num_alt + 1 \n",
    "    variant_hq = quality_set & snp_set & vsqlod_set & alt_set\n",
    "    return(variant_hq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allele_freq(callset, variant_bool, sample_bool, num_alt):\n",
    "    gt_daskSub = gt_subset(callset, variant_bool, sample_bool)\n",
    "    # count number of alleles\n",
    "    ac = gt_daskSub.count_alleles(max_allele=num_alt)\n",
    "    sub_af = ac/ac.sum(axis=1, keepdims=True)\n",
    "    sub_df = pd.DataFrame(sub_af,\n",
    "                 index=[\"Pf3D7_\" + chrom + \"_v3:\" + str(x) for x in np.array(callset['variants/POS'][:])[variant_bool]],\n",
    "                 columns=[\"REF\"] + [\"ALT\" + str(x) for x in range(1, num_alt + 1)])\n",
    "    return(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt_merge(list1, list2, j):\n",
    "    dic = {-1:\"X\", \n",
    "           0: np.array(callset['variants/REF'][:])[variant_bool][j], \n",
    "           1: np.array(callset['variants/ALT'][:])[variant_bool][j,0], \n",
    "           2: np.array(callset['variants/ALT'][:])[variant_bool][j,1],\n",
    "           3: np.array(callset['variants/ALT'][:])[variant_bool][j,2]}\n",
    "    merged_list = []\n",
    "    for i in range(0, len(list1)):\n",
    "        if list1[i] == list2[i]:\n",
    "            if list1[i] == -1:\n",
    "                merged_list.append(\"X\")\n",
    "            else:\n",
    "                merged_list.append(list1[i])\n",
    "        else:\n",
    "            merged_list.append(\"N\") \n",
    "    merged_replace=[dic.get(n, n) for n in merged_list]  \n",
    "    return(merged_replace)\n",
    "\n",
    "def match_genotype(callset, variant_bool, sample_bool):\n",
    "    gt_daskSub = gt_subset(callset, variant_bool, sample_bool)\n",
    "    data =[]\n",
    "    for j in range(0, len(gt_daskSub)):\n",
    "        data.append(gt_merge(gt_daskSub[j,:,0], gt_daskSub[j,:,1], j))\n",
    "    gt_df = pd.DataFrame(data,\n",
    "                 index=[\"Pf3D7_\" + chrom + \"_v3:\" + str(x) for x in np.array(callset['variants/POS'][:])[variant_bool]],\n",
    "                 columns=list(compress(np.array(callset['samples']).tolist(), sample_bool)))\n",
    "    return(gt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it together \n",
    "\n",
    "This section is specifically set up to run a for loop since Pf3k was divivde by chromosome. For other data sets, the above functions except reading in zarr object, should hold asumping it contains the same information in the Zarr file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pf3D7_01_v3</td>\n",
       "      <td>130339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pf3D7_01_v3</td>\n",
       "      <td>537322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pf3D7_02_v3</td>\n",
       "      <td>842805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pf3D7_04_v3</td>\n",
       "      <td>276127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pf3D7_05_v3</td>\n",
       "      <td>931606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pf3D7_06_v3</td>\n",
       "      <td>145475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pf3D7_06_v3</td>\n",
       "      <td>937752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pf3D7_07_v3</td>\n",
       "      <td>221722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pf3D7_07_v3</td>\n",
       "      <td>435497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pf3D7_07_v3</td>\n",
       "      <td>489666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pf3D7_07_v3</td>\n",
       "      <td>602559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pf3D7_07_v3</td>\n",
       "      <td>616459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pf3D7_07_v3</td>\n",
       "      <td>628392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pf3D7_07_v3</td>\n",
       "      <td>736978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pf3D7_07_v3</td>\n",
       "      <td>1359804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pf3D7_08_v3</td>\n",
       "      <td>612596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pf3D7_09_v3</td>\n",
       "      <td>634019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pf3D7_10_v3</td>\n",
       "      <td>82375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pf3D7_10_v3</td>\n",
       "      <td>1402510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pf3D7_11_v3</td>\n",
       "      <td>119497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pf3D7_11_v3</td>\n",
       "      <td>408600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pf3D7_13_v3</td>\n",
       "      <td>158412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Pf3D7_13_v3</td>\n",
       "      <td>1429067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Pf3D7_14_v3</td>\n",
       "      <td>755731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            chr  position\n",
       "0   Pf3D7_01_v3    130339\n",
       "1   Pf3D7_01_v3    537322\n",
       "2   Pf3D7_02_v3    842805\n",
       "3   Pf3D7_04_v3    276127\n",
       "4   Pf3D7_05_v3    931606\n",
       "5   Pf3D7_06_v3    145475\n",
       "6   Pf3D7_06_v3    937752\n",
       "7   Pf3D7_07_v3    221722\n",
       "8   Pf3D7_07_v3    435497\n",
       "9   Pf3D7_07_v3    489666\n",
       "10  Pf3D7_07_v3    602559\n",
       "11  Pf3D7_07_v3    616459\n",
       "12  Pf3D7_07_v3    628392\n",
       "13  Pf3D7_07_v3    736978\n",
       "14  Pf3D7_07_v3   1359804\n",
       "15  Pf3D7_08_v3    612596\n",
       "16  Pf3D7_09_v3    634019\n",
       "17  Pf3D7_10_v3     82375\n",
       "18  Pf3D7_10_v3   1402510\n",
       "19  Pf3D7_11_v3    119497\n",
       "20  Pf3D7_11_v3    408600\n",
       "21  Pf3D7_13_v3    158412\n",
       "22  Pf3D7_13_v3   1429067\n",
       "23  Pf3D7_14_v3    755731"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the SNPs of interest - i.e. 24 barcode positions\n",
    "project_dir = '/home/jribado/Dropbox (IDM)/parasite_genetics/genomics/senegal'\n",
    "user_snp_file = os.path.join(project_dir, \"2008Daniels_BarcodePositions_Updated.txt\")\n",
    "user_snp_df = pd.read_csv(user_snp_file, sep='\\t', header=0)\n",
    "user_snp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SenP008', 'SenP011', 'SenP019', 'SenP027']\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "user_samples = '/home/jribado/Dropbox (IDM)/parasite_genetics/genomics/senegal/pf3k_bc_sampleOverlap.txt'\n",
    "with open(user_samples) as f:\n",
    "    sampleList = f.read().splitlines() \n",
    "print(sampleList[1:5])\n",
    "print(len(sampleList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         REF      ALT1  ALT2  ALT3\n",
      "Pf3D7_01_v3:130339  0.302920  0.697080   0.0   0.0\n",
      "Pf3D7_01_v3:537322  0.021898  0.978102   0.0   0.0\n",
      "                   SenP005.02 SenP008.04 SenP011.02 SenP019.04 SenP027.02  \\\n",
      "Pf3D7_01_v3:130339          C          T          T          C          C   \n",
      "Pf3D7_01_v3:537322          A          A          A          A          A   \n",
      "\n",
      "                   SenP031.01 SenP051.02 SenP060.02 SenT001.08 SenT001.11  \\\n",
      "Pf3D7_01_v3:130339          T          C          T          T          N   \n",
      "Pf3D7_01_v3:537322          A          A          A          A          A   \n",
      "\n",
      "                    ... SenT230.08 SenT231.08 SenT232.08 SenT233.08  \\\n",
      "Pf3D7_01_v3:130339  ...          T          T          T          T   \n",
      "Pf3D7_01_v3:537322  ...          A          A          A          A   \n",
      "\n",
      "                   SenT235.08 SenT236.08 SenV034.04 SenV035.04 SenV042.05  \\\n",
      "Pf3D7_01_v3:130339          T          C          C          T          T   \n",
      "Pf3D7_01_v3:537322          A          A          A          A          A   \n",
      "\n",
      "                   SenV092.05  \n",
      "Pf3D7_01_v3:130339          T  \n",
      "Pf3D7_01_v3:537322          A  \n",
      "\n",
      "[2 rows x 137 columns]\n"
     ]
    }
   ],
   "source": [
    "project_dir = '/home/jribado/Dropbox (IDM)/parasite_genetics/genomics/senegal/'\n",
    "num_alt = 3\n",
    "genotypes, frequencies = [], []\n",
    "\n",
    "\n",
    "for i in range(1, 2):\n",
    "    chrom = \"{:02d}\".format(i)\n",
    "    # read in file\n",
    "    zarr_path = '/home/jribado/Dropbox (IDM)/Data, Dynamics, and Analytics Folder/Projects/malaria_pfcommunity/malaria_pf3k/pf3k_zarr/'\n",
    "    callset = read_zarr(chrom, zarr_path)\n",
    "    # identify variants in VCF that match user inputs\n",
    "    user_chrom_snps = user_snps(user_snp_df, chrom)\n",
    "    variant_bool = overlap_filter(overlap_avail(user_chrom_snps, callset), \n",
    "                                  variant_filter(callset, 2, num_alt))\n",
    "    # identify samples in VCF that match user inputs\n",
    "    sample_list = [x.split(\".\")[0] for x in np.array(callset['samples']).tolist()]\n",
    "    sample_bool = np.array([i in sampleList for i in sample_list]) \n",
    "    #sample_bool  = np.array([\"Sen\" in i for i in np.array(callset['samples']).tolist()])\n",
    "    freq = allele_freq(callset, variant_bool, sample_bool, 3)\n",
    "    frequencies.append(freq)\n",
    "    geno = match_genotype(callset, variant_bool, sample_bool)\n",
    "    genotypes.append(geno)\n",
    "\n",
    "appended_freq = pd.concat(frequencies)\n",
    "print(appended_freq)\n",
    "#appended_freq.to_csv('~/Desktop/Pf3k_wgsSenegalBCOverlapFrequencies24bc.txt') \n",
    "\n",
    "appended_geno = pd.concat(genotypes)\n",
    "print(appended_geno)\n",
    "#appended_geno.to_csv('~/Desktop/Pf3k_wgsSenegalBCOverlapsHaploidGenotype24bc.txt')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'compute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-fea7c7311c01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdp_dask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAlleleCountsDaskArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdp_zarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdp_variant_selection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdp_dask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariant_bool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdp_variant_selection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdp_variant_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_bool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'compute'"
     ]
    }
   ],
   "source": [
    "# pull total number of high quality reads that align to each position per sample\n",
    "dp_zarr = callset['calldata/DP']\n",
    "dp_dask = allel.AlleleCountsDaskArray(dp_zarr)\n",
    "dp_variant_selection = dp_dask.compress(variant_bool, axis=0).compute()\n",
    "dp_variant_selection = dp_variant_selection.compress(sample_bool, axis=1).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(variant_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
