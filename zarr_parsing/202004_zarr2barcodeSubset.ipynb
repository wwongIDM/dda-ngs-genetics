{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating matrices of SNPs from VCF files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Learn to subset variants from Zarr files that can be used in IDM models. \n",
    "\n",
    "The Zarr format is similar to HD5 that will allows to subset large files without loading into memory. For any whole genome sequencing file, variants in a population will be in a VCF format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages - have been installed in vcf virtual env\n",
    "import os, sys\n",
    "import zarr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import allel  \n",
    "import dask.array as da\n",
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load literature position files\n",
    "\n",
    "These positions files were obtained from Rachel Daniels on 05/07/2020, which updated the positions in the 2008 paper to the Pf3D7v3.1 reference Pf3k WGS samples are aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variants from user:  24\n"
     ]
    }
   ],
   "source": [
    "pos_dir = '/home/jribado/Dropbox (IDM)/parasite_genetics/genomics/senegal'\n",
    "daniels_df = pd.read_csv(os.path.join(pos_dir, \"2008Daniels_BarcodePositions_Updated.txt\"), sep='\\t', header=0)\n",
    "# create a list with the chromosome and position for each study\n",
    "# daniels_pos = [x + \"_\" + str(y) for x, y in zip([\"{:02d}\".format(x) for x in daniels_df[\"chr\"]], daniels_df[\"position\"].tolist())]\n",
    "print(\"Number of variants from user: \", daniels_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load variant file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in zarr files\n",
    "chrom = 7\n",
    "zarr_path = '/home/jribado/Dropbox (IDM)/Data, Dynamics, and Analytics Folder/Projects/malaria_pfcommunity/malaria_pf3k/pf3k_zarr/'\n",
    "zarr_file = zarr_path + 'SNP_INDEL_Pf3D7_' + \"{:02d}\".format(chrom) + '_v3.zarr'\n",
    "callset = zarr.open(zarr_file, mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find index overlaps\n",
    "\n",
    "This looks for overlaps without considering quality filtering parameters. Quality metric are applied in the following section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible variants on chromosome 7 : 300181\n"
     ]
    }
   ],
   "source": [
    "# get the chromosome and position for all possible variants\n",
    "zarr_chrom = [x.split(\"_\",2)[1] for x in callset['variants/CHROM'][:].tolist()]\n",
    "zarr_index = callset['variants/POS'][:].tolist()\n",
    "print(\"Possible variants on chromosome\", chrom, \":\", len(zarr_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible variants on chromosome 7 from user defined variant list : 8\n",
      "[221722, 435497, 489666, 602559, 616459, 628392, 736978, 1359804]\n"
     ]
    }
   ],
   "source": [
    "# subset the variants on the chromosome of interest\n",
    "#daniels_chrom_sub = daniels_df.loc[daniels_df.chr == chrom]\n",
    "daniels_df['chr']\n",
    "daniels_chrom_sub = daniels_df[daniels_df['chr'].str.contains(\"{:02d}\".format(chrom))]\n",
    "print(\"Possible variants on chromosome\", chrom, \"from user defined variant list :\", daniels_chrom_sub.shape[0])\n",
    "print(daniels_chrom_sub[\"position\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of overlapping variants from VCF and user defined variant list on chromosome 7 : 8\n",
      "Overlapping positions on chromsome 7 : [ 58951  87768  95123 158078 160895 162482 177615 260960]\n"
     ]
    }
   ],
   "source": [
    "user_overlap = [i in daniels_chrom_sub[\"position\"].tolist() for i in zarr_index]\n",
    "print(\"Number of overlapping variants from VCF and user defined variant list on chromosome\", chrom, \":\", np.count_nonzero(user_overlap))\n",
    "print(\"Overlapping positions on chromsome\", chrom, \":\", np.where(user_overlap)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! The updated positions are in the VCF file, which means we can rely on standard recalibration calls to minimize errors :). \n",
    "\n",
    "We are less concerned about non-Senegal samples at the moment. We can filter those out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['SenP005.02',\n",
       " 'SenP008.04',\n",
       " 'SenP011.02',\n",
       " 'SenP019.04',\n",
       " 'SenP027.02',\n",
       " 'SenP031.01',\n",
       " 'SenP051.02',\n",
       " 'SenP060.02',\n",
       " 'SenT001.08',\n",
       " 'SenT001.11',\n",
       " 'SenT002.07',\n",
       " 'SenT002.09',\n",
       " 'SenT004.10',\n",
       " 'SenT008.10',\n",
       " 'SenT009.10',\n",
       " 'SenT011.09',\n",
       " 'SenT013.11',\n",
       " 'SenT015.09',\n",
       " 'SenT015.11',\n",
       " 'SenT021.09',\n",
       " 'SenT022.09',\n",
       " 'SenT022.11',\n",
       " 'SenT024.10',\n",
       " 'SenT025.10',\n",
       " 'SenT026.10',\n",
       " 'SenT029.09',\n",
       " 'SenT030.11',\n",
       " 'SenT032.09',\n",
       " 'SenT033.08',\n",
       " 'SenT033.09',\n",
       " 'SenT036.10',\n",
       " 'SenT037.09',\n",
       " 'SenT040.11',\n",
       " 'SenT042.09',\n",
       " 'SenT044.10',\n",
       " 'SenT044.11',\n",
       " 'SenT045.10',\n",
       " 'SenT045.11',\n",
       " 'SenT046.10',\n",
       " 'SenT046.11',\n",
       " 'SenT047.09',\n",
       " 'SenT052.11',\n",
       " 'SenT053.11',\n",
       " 'SenT055.11',\n",
       " 'SenT058.10',\n",
       " 'SenT058.11',\n",
       " 'SenT061.09',\n",
       " 'SenT063.07',\n",
       " 'SenT064.10',\n",
       " 'SenT066.08',\n",
       " 'SenT067.09',\n",
       " 'SenT067.11',\n",
       " 'SenT069.11',\n",
       " 'SenT072.11',\n",
       " 'SenT074.10',\n",
       " 'SenT074.11',\n",
       " 'SenT075.10',\n",
       " 'SenT077.08',\n",
       " 'SenT077.11',\n",
       " 'SenT078.10',\n",
       " 'SenT080.10',\n",
       " 'SenT081.10',\n",
       " 'SenT082.10',\n",
       " 'SenT084.09',\n",
       " 'SenT084.10',\n",
       " 'SenT084.11',\n",
       " 'SenT085.10',\n",
       " 'SenT086.09',\n",
       " 'SenT086.10',\n",
       " 'SenT087.08',\n",
       " 'SenT087.09',\n",
       " 'SenT087.11',\n",
       " 'SenT090.09',\n",
       " 'SenT092.08',\n",
       " 'SenT094.09',\n",
       " 'SenT097.09',\n",
       " 'SenT097.11',\n",
       " 'SenT102.08',\n",
       " 'SenT104.07',\n",
       " 'SenT105.07',\n",
       " 'SenT106.08',\n",
       " 'SenT110.09',\n",
       " 'SenT111.09',\n",
       " 'SenT112.09',\n",
       " 'SenT113.09',\n",
       " 'SenT114.09',\n",
       " 'SenT117.08',\n",
       " 'SenT119.09',\n",
       " 'SenT120.11',\n",
       " 'SenT123.09',\n",
       " 'SenT124.10',\n",
       " 'SenT124.11',\n",
       " 'SenT125.11',\n",
       " 'SenT127.09',\n",
       " 'SenT128.08',\n",
       " 'SenT128.09',\n",
       " 'SenT129.11',\n",
       " 'SenT130.09',\n",
       " 'SenT130.11',\n",
       " 'SenT133.11',\n",
       " 'SenT135.09',\n",
       " 'SenT136.09',\n",
       " 'SenT136.11',\n",
       " 'SenT137.09',\n",
       " 'SenT138.11',\n",
       " 'SenT139.11',\n",
       " 'SenT140.11',\n",
       " 'SenT142.09',\n",
       " 'SenT142.11',\n",
       " 'SenT143.09',\n",
       " 'SenT148.09',\n",
       " 'SenT149.09',\n",
       " 'SenT150.09',\n",
       " 'SenT151.08',\n",
       " 'SenT151.09',\n",
       " 'SenT165.09',\n",
       " 'SenT166.09',\n",
       " 'SenT170.08',\n",
       " 'SenT179.08',\n",
       " 'SenT180.08',\n",
       " 'SenT181.10',\n",
       " 'SenT184.09',\n",
       " 'SenT185.10',\n",
       " 'SenT187.09',\n",
       " 'SenT190.09',\n",
       " 'SenT224.08',\n",
       " 'SenT227.08',\n",
       " 'SenT230.08',\n",
       " 'SenT231.08',\n",
       " 'SenT232.08',\n",
       " 'SenT233.08',\n",
       " 'SenT235.08',\n",
       " 'SenT236.08',\n",
       " 'SenV034.04',\n",
       " 'SenV035.04',\n",
       " 'SenV042.05',\n",
       " 'SenV092.05']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_bool = np.array([\"Sen\" in i for i in np.array(callset['samples']).tolist()])\n",
    "print(np.count_nonzero(sen_bool))\n",
    "sen_names = list(compress(np.array(callset['samples']).tolist(), sen_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull variant information\n",
    "\n",
    "Now that fun part, actually getting the relevant information! These two sections will highlight pulling genotypes or count information for different alleles. \n",
    "\n",
    "I recommend filtering the variants based on MalariaGen guidelines. The two variables that can be relaxed below ate the number of alternative alleles and the VSQLOD score. Currently it is set to only pull biallelic SNPs, but can be changed to pull muliallelic sites. The VSQLOD score is a ratio of SNP position testing Gaussian mixture models for the probability of true SNPs in a good and bad model. The higher the score, the more confident you can be in the call. Anything above 1 is considered technucally \"true\" if this needs to be relaxed to include more variants (Pfv6 uses a filter of 6). \n",
    "\n",
    "More info on VQSLOD scores: https://qcb.ucla.edu/wp-content/uploads/sites/14/2016/03/GATKwr12-6-Variant_filtering.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered genes: 46029\n"
     ]
    }
   ],
   "source": [
    "# get high quality snps for pfv6 to find overlaps\n",
    "quality_set = callset['variants/FILTER_PASS'][:]\n",
    "snp_set = callset['variants/is_snp'][:]\n",
    "vsqlod_set = callset['variants/VQSLOD'][:]  > 2\n",
    "biallelic_set = callset['variants/numalt'][:] < 2\n",
    "variant_hq = quality_set & snp_set & vsqlod_set & biallelic_set\n",
    "print(\"Number of filtered genes:\", np.count_nonzero(variant_hq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variant_keep = quality_set & snp_set & vsqlod_set & biallelic_set & user_overlap\n",
    "print(type(variant_keep))\n",
    "np.count_nonzero(variant_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genotype matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_zarr = callset['calldata/GT']\n",
    "gt_dask = allel.GenotypeDaskArray(gt_zarr)\n",
    "gt_daskSub = gt_dask.subset(user_overlap, sen_bool).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"allel allel-DisplayAs2D\"><span>&lt;GenotypeArray shape=(8, 137, 2) dtype=int8&gt;</span><table><thead><tr><th></th><th style=\"text-align: center\">0</th><th style=\"text-align: center\">1</th><th style=\"text-align: center\">2</th><th style=\"text-align: center\">3</th><th style=\"text-align: center\">4</th><th style=\"text-align: center\">...</th><th style=\"text-align: center\">132</th><th style=\"text-align: center\">133</th><th style=\"text-align: center\">134</th><th style=\"text-align: center\">135</th><th style=\"text-align: center\">136</th></tr></thead><tbody><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">0</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/1</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">1</th><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">2</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">...</th><td style=\"text-align: center\" colspan=\"12\">...</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">5</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">6</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">7</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/2</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">2/2</td><td style=\"text-align: center\">1/1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "<GenotypeArray shape=(8, 137, 2) dtype=int8>\n",
       "0/0 0/1 1/1 0/0 1/1 ... 0/0 0/0 0/0 0/0 0/0\n",
       "1/1 0/0 0/0 0/0 1/1 ... 0/0 1/1 0/0 0/0 0/0\n",
       "0/0 0/0 0/0 1/1 1/1 ... 0/0 1/1 1/1 1/1 0/0\n",
       "...\n",
       "0/0 0/0 1/1 0/0 0/0 ... 1/1 0/0 1/1 1/1 1/1\n",
       "0/0 0/1 0/0 0/0 1/1 ... 1/1 1/1 1/1 1/1 1/1\n",
       "0/0 0/2 0/0 1/1 0/0 ... 0/0 0/0 1/1 2/2 1/1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_daskSub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not an elegant \"Pythonic way\" to pull genotypes, but it works. Would be thrilled to learn a better way to loop through 3D Numpy arrays to make this faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt_merge(list1, list2, j):\n",
    "    dic = {-1:\"X\", \n",
    "           0: np.array(callset['variants/REF'][:])[user_overlap][j], \n",
    "           1: np.array(callset['variants/ALT'][:])[user_overlap][j,0], \n",
    "           2: np.array(callset['variants/ALT'][:])[user_overlap][j,1],\n",
    "           3: np.array(callset['variants/ALT'][:])[user_overlap][j,2]}\n",
    "    merged_list = []\n",
    "    for i in range(0, len(list1)):\n",
    "        if list1[i] == list2[i]:\n",
    "            if list1[i] == -1:\n",
    "                merged_list.append(\"X\")\n",
    "            else:\n",
    "                merged_list.append(list1[i])\n",
    "        else:\n",
    "            merged_list.append(\"N\") \n",
    "    merged_replace=[dic.get(n, n) for n in merged_list]  \n",
    "    return(merged_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    SenP005.02 SenP008.04 SenP011.02 SenP019.04 SenP027.02  \\\n",
      "Pf3D7_07_v3:221722           G          N          A          G          A   \n",
      "Pf3D7_07_v3:435497           T          A          A          A          T   \n",
      "Pf3D7_07_v3:489666           C          C          C          T          T   \n",
      "Pf3D7_07_v3:602559           T          N          C          T          C   \n",
      "Pf3D7_07_v3:616459           A          G          G          G          G   \n",
      "Pf3D7_07_v3:628392           C          C          T          C          C   \n",
      "Pf3D7_07_v3:736978           A          N          A          A          C   \n",
      "Pf3D7_07_v3:1359804          C          N          C          A          C   \n",
      "\n",
      "                    SenP031.01 SenP051.02 SenP060.02 SenT001.08 SenT001.11  \\\n",
      "Pf3D7_07_v3:221722           A          G          G          G          N   \n",
      "Pf3D7_07_v3:435497           A          T          A          T          T   \n",
      "Pf3D7_07_v3:489666           T          T          C          C          N   \n",
      "Pf3D7_07_v3:602559           C          T          X          C          N   \n",
      "Pf3D7_07_v3:616459           G          A          A          G          G   \n",
      "Pf3D7_07_v3:628392           C          T          C          T          N   \n",
      "Pf3D7_07_v3:736978           A          C          A          C          N   \n",
      "Pf3D7_07_v3:1359804          C          A          C          C          N   \n",
      "\n",
      "                     ... SenT230.08 SenT231.08 SenT232.08 SenT233.08  \\\n",
      "Pf3D7_07_v3:221722   ...          A          G          G          G   \n",
      "Pf3D7_07_v3:435497   ...          A          T          A          T   \n",
      "Pf3D7_07_v3:489666   ...          T          C          T          C   \n",
      "Pf3D7_07_v3:602559   ...          X          T          T          T   \n",
      "Pf3D7_07_v3:616459   ...          G          A          G          A   \n",
      "Pf3D7_07_v3:628392   ...          C          C          T          C   \n",
      "Pf3D7_07_v3:736978   ...          A          A          A          C   \n",
      "Pf3D7_07_v3:1359804  ...          C          A          C          A   \n",
      "\n",
      "                    SenT235.08 SenT236.08 SenV034.04 SenV035.04 SenV042.05  \\\n",
      "Pf3D7_07_v3:221722           G          G          G          G          G   \n",
      "Pf3D7_07_v3:435497           A          A          T          A          A   \n",
      "Pf3D7_07_v3:489666           T          C          T          T          T   \n",
      "Pf3D7_07_v3:602559           T          T          T          T          T   \n",
      "Pf3D7_07_v3:616459           G          G          A          G          A   \n",
      "Pf3D7_07_v3:628392           T          T          C          T          T   \n",
      "Pf3D7_07_v3:736978           A          C          C          C          C   \n",
      "Pf3D7_07_v3:1359804          C          C          C          A          G   \n",
      "\n",
      "                    SenV092.05  \n",
      "Pf3D7_07_v3:221722           G  \n",
      "Pf3D7_07_v3:435497           A  \n",
      "Pf3D7_07_v3:489666           C  \n",
      "Pf3D7_07_v3:602559           T  \n",
      "Pf3D7_07_v3:616459           G  \n",
      "Pf3D7_07_v3:628392           T  \n",
      "Pf3D7_07_v3:736978           C  \n",
      "Pf3D7_07_v3:1359804          A  \n",
      "\n",
      "[8 rows x 137 columns]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for j in range(0, len(gt_daskSub)):\n",
    "    data.append(gt_merge(gt_daskSub[j,:,0], gt_daskSub[j,:,1], j))\n",
    "df = pd.DataFrame(data,\n",
    "                 index=[\"Pf3D7_\" + str(\"{:02d}\".format(chrom)) + \"_v3:\" + str(x) for x in np.array(callset['variants/POS'][:])[user_overlap]],\n",
    "                 columns=sen_names)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts matrix\n",
    "\n",
    "The counts matrix would give a good sense for the proportion of reads that align to each allele. This is great to consider if expanding any models to handle polyinfections at \"biallelic\" sites or multiallelic sites. Change the allele count array to pull the 1, 2, 3..,n allele in each sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull total number of high quality reads that align to each position per sample\n",
    "dp_zarr = callset['calldata/DP']\n",
    "dp_dask = allel.AlleleCountsDaskArray(dp_zarr)\n",
    "dp_variant_selection = dp_dask.compress(user_overlap, axis=0).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 168.96 kB </td> <td> 2.05 kB </td></tr>\n",
       "    <tr><th> Shape </th><td> (8, 2640, 4) </td> <td> (4, 64, 4) </td></tr>\n",
       "    <tr><th> Count </th><td> 379 Tasks </td><td> 168 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> int16 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"100\" height=\"184\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"2\" x2=\"24\" y2=\"17\" />\n",
       "  <line x1=\"10\" y1=\"5\" x2=\"24\" y2=\"20\" />\n",
       "  <line x1=\"10\" y1=\"8\" x2=\"24\" y2=\"23\" />\n",
       "  <line x1=\"10\" y1=\"11\" x2=\"24\" y2=\"26\" />\n",
       "  <line x1=\"10\" y1=\"14\" x2=\"24\" y2=\"29\" />\n",
       "  <line x1=\"10\" y1=\"17\" x2=\"24\" y2=\"32\" />\n",
       "  <line x1=\"10\" y1=\"20\" x2=\"24\" y2=\"35\" />\n",
       "  <line x1=\"10\" y1=\"23\" x2=\"24\" y2=\"38\" />\n",
       "  <line x1=\"10\" y1=\"26\" x2=\"24\" y2=\"41\" />\n",
       "  <line x1=\"10\" y1=\"29\" x2=\"24\" y2=\"44\" />\n",
       "  <line x1=\"10\" y1=\"32\" x2=\"24\" y2=\"46\" />\n",
       "  <line x1=\"10\" y1=\"34\" x2=\"24\" y2=\"49\" />\n",
       "  <line x1=\"10\" y1=\"37\" x2=\"24\" y2=\"52\" />\n",
       "  <line x1=\"10\" y1=\"40\" x2=\"24\" y2=\"55\" />\n",
       "  <line x1=\"10\" y1=\"43\" x2=\"24\" y2=\"58\" />\n",
       "  <line x1=\"10\" y1=\"46\" x2=\"24\" y2=\"61\" />\n",
       "  <line x1=\"10\" y1=\"49\" x2=\"24\" y2=\"64\" />\n",
       "  <line x1=\"10\" y1=\"52\" x2=\"24\" y2=\"67\" />\n",
       "  <line x1=\"10\" y1=\"55\" x2=\"24\" y2=\"70\" />\n",
       "  <line x1=\"10\" y1=\"58\" x2=\"24\" y2=\"73\" />\n",
       "  <line x1=\"10\" y1=\"61\" x2=\"24\" y2=\"76\" />\n",
       "  <line x1=\"10\" y1=\"64\" x2=\"24\" y2=\"78\" />\n",
       "  <line x1=\"10\" y1=\"66\" x2=\"24\" y2=\"81\" />\n",
       "  <line x1=\"10\" y1=\"69\" x2=\"24\" y2=\"84\" />\n",
       "  <line x1=\"10\" y1=\"72\" x2=\"24\" y2=\"87\" />\n",
       "  <line x1=\"10\" y1=\"75\" x2=\"24\" y2=\"90\" />\n",
       "  <line x1=\"10\" y1=\"78\" x2=\"24\" y2=\"93\" />\n",
       "  <line x1=\"10\" y1=\"81\" x2=\"24\" y2=\"96\" />\n",
       "  <line x1=\"10\" y1=\"84\" x2=\"24\" y2=\"99\" />\n",
       "  <line x1=\"10\" y1=\"87\" x2=\"24\" y2=\"102\" />\n",
       "  <line x1=\"10\" y1=\"90\" x2=\"24\" y2=\"105\" />\n",
       "  <line x1=\"10\" y1=\"93\" x2=\"24\" y2=\"108\" />\n",
       "  <line x1=\"10\" y1=\"96\" x2=\"24\" y2=\"110\" />\n",
       "  <line x1=\"10\" y1=\"98\" x2=\"24\" y2=\"113\" />\n",
       "  <line x1=\"10\" y1=\"101\" x2=\"24\" y2=\"116\" />\n",
       "  <line x1=\"10\" y1=\"104\" x2=\"24\" y2=\"119\" />\n",
       "  <line x1=\"10\" y1=\"107\" x2=\"24\" y2=\"122\" />\n",
       "  <line x1=\"10\" y1=\"110\" x2=\"24\" y2=\"125\" />\n",
       "  <line x1=\"10\" y1=\"113\" x2=\"24\" y2=\"128\" />\n",
       "  <line x1=\"10\" y1=\"116\" x2=\"24\" y2=\"131\" />\n",
       "  <line x1=\"10\" y1=\"119\" x2=\"24\" y2=\"134\" />\n",
       "  <line x1=\"10\" y1=\"120\" x2=\"24\" y2=\"134\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"11\" y2=\"121\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"125\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"133\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"134\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.000000,0.000000 24.948598,14.948598 24.948598,134.948598 10.000000,120.000000\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"37\" y2=\"1\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"41\" y2=\"5\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"48\" y2=\"13\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"50\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"35\" y1=\"0\" x2=\"50\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.000000,0.000000 35.412617,0.000000 50.361214,14.948598 24.948598,14.948598\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"50\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"24\" y1=\"17\" x2=\"50\" y2=\"17\" />\n",
       "  <line x1=\"24\" y1=\"20\" x2=\"50\" y2=\"20\" />\n",
       "  <line x1=\"24\" y1=\"23\" x2=\"50\" y2=\"23\" />\n",
       "  <line x1=\"24\" y1=\"26\" x2=\"50\" y2=\"26\" />\n",
       "  <line x1=\"24\" y1=\"29\" x2=\"50\" y2=\"29\" />\n",
       "  <line x1=\"24\" y1=\"32\" x2=\"50\" y2=\"32\" />\n",
       "  <line x1=\"24\" y1=\"35\" x2=\"50\" y2=\"35\" />\n",
       "  <line x1=\"24\" y1=\"38\" x2=\"50\" y2=\"38\" />\n",
       "  <line x1=\"24\" y1=\"41\" x2=\"50\" y2=\"41\" />\n",
       "  <line x1=\"24\" y1=\"44\" x2=\"50\" y2=\"44\" />\n",
       "  <line x1=\"24\" y1=\"46\" x2=\"50\" y2=\"46\" />\n",
       "  <line x1=\"24\" y1=\"49\" x2=\"50\" y2=\"49\" />\n",
       "  <line x1=\"24\" y1=\"52\" x2=\"50\" y2=\"52\" />\n",
       "  <line x1=\"24\" y1=\"55\" x2=\"50\" y2=\"55\" />\n",
       "  <line x1=\"24\" y1=\"58\" x2=\"50\" y2=\"58\" />\n",
       "  <line x1=\"24\" y1=\"61\" x2=\"50\" y2=\"61\" />\n",
       "  <line x1=\"24\" y1=\"64\" x2=\"50\" y2=\"64\" />\n",
       "  <line x1=\"24\" y1=\"67\" x2=\"50\" y2=\"67\" />\n",
       "  <line x1=\"24\" y1=\"70\" x2=\"50\" y2=\"70\" />\n",
       "  <line x1=\"24\" y1=\"73\" x2=\"50\" y2=\"73\" />\n",
       "  <line x1=\"24\" y1=\"76\" x2=\"50\" y2=\"76\" />\n",
       "  <line x1=\"24\" y1=\"78\" x2=\"50\" y2=\"78\" />\n",
       "  <line x1=\"24\" y1=\"81\" x2=\"50\" y2=\"81\" />\n",
       "  <line x1=\"24\" y1=\"84\" x2=\"50\" y2=\"84\" />\n",
       "  <line x1=\"24\" y1=\"87\" x2=\"50\" y2=\"87\" />\n",
       "  <line x1=\"24\" y1=\"90\" x2=\"50\" y2=\"90\" />\n",
       "  <line x1=\"24\" y1=\"93\" x2=\"50\" y2=\"93\" />\n",
       "  <line x1=\"24\" y1=\"96\" x2=\"50\" y2=\"96\" />\n",
       "  <line x1=\"24\" y1=\"99\" x2=\"50\" y2=\"99\" />\n",
       "  <line x1=\"24\" y1=\"102\" x2=\"50\" y2=\"102\" />\n",
       "  <line x1=\"24\" y1=\"105\" x2=\"50\" y2=\"105\" />\n",
       "  <line x1=\"24\" y1=\"108\" x2=\"50\" y2=\"108\" />\n",
       "  <line x1=\"24\" y1=\"110\" x2=\"50\" y2=\"110\" />\n",
       "  <line x1=\"24\" y1=\"113\" x2=\"50\" y2=\"113\" />\n",
       "  <line x1=\"24\" y1=\"116\" x2=\"50\" y2=\"116\" />\n",
       "  <line x1=\"24\" y1=\"119\" x2=\"50\" y2=\"119\" />\n",
       "  <line x1=\"24\" y1=\"122\" x2=\"50\" y2=\"122\" />\n",
       "  <line x1=\"24\" y1=\"125\" x2=\"50\" y2=\"125\" />\n",
       "  <line x1=\"24\" y1=\"128\" x2=\"50\" y2=\"128\" />\n",
       "  <line x1=\"24\" y1=\"131\" x2=\"50\" y2=\"131\" />\n",
       "  <line x1=\"24\" y1=\"134\" x2=\"50\" y2=\"134\" />\n",
       "  <line x1=\"24\" y1=\"134\" x2=\"50\" y2=\"134\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"134\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"50\" y1=\"14\" x2=\"50\" y2=\"134\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"24.948598,14.948598 50.361214,14.948598 50.361214,134.948598 24.948598,134.948598\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"37.654906\" y=\"154.948598\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >4</text>\n",
       "  <text x=\"70.361214\" y=\"74.948598\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,70.361214,74.948598)\">2640</text>\n",
       "  <text x=\"7.474299\" y=\"147.474299\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,7.474299,147.474299)\">8</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<getitem, shape=(8, 2640, 4), dtype=int16, chunksize=(4, 64, 4), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_variant_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of reads that align to each of the alleles\n",
    "ad_zarr=callset['calldata/AD']\n",
    "ad_array=da.from_zarr(ad_zarr)\n",
    "ad_variant_selection=ad_array[user_overlap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull the first item in the allele count array to get the reference count\n",
    "ad_array_ref=ad_variant_selection[:,:,0]\n",
    "ad_array_ref=ad_array_ref.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check both data frames have the same dimension\n",
    "np.shape(ad_array_ref) == np.shape(dp_variant_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore zero division for site where one population may have an allele but other samples may not have adequate coverage\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "ref_het_calc=ad_array_ref/dp_variant_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the row names that correspond to the chromosome and position\n",
    "pos_keep = np.where(user_overlap)[0]\n",
    "chrom = [\"chr\"+x.split(\"_\",2)[1] for x in callset['variants/CHROM'][:][pos_keep].tolist()]\n",
    "pos = callset['variants/POS'][:][pos_keep].tolist()\n",
    "pos_index = [x + \"_\" + str(y) for x, y in zip(chrom, pos)]\n",
    "\n",
    "het_df=pd.DataFrame(data=ref_het_calc,\n",
    "                     index=pos_index,\n",
    "                     columns=callset['samples'])\n",
    "het_df\n",
    "het_df.to_csv('~/Desktop/alleleCounts_test.csv', header=True, index=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
